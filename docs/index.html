<!DOCTYPE html>
<html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project
  | Georgia Tech | Fall 2018: CS 6476 </title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">


<!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>

<link href="css/bootstrap-responsive.min.css" rel="stylesheet">
</head>

<body>
<div class="container">
<div class="page-header">



<!-- Title and Name -->
<h1>PetSwap</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Hemanth Chittanuru,
  Kenny Scharm, Raghav Raj Mittal, Sarah Li</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">CS 6476 Computer Vision - Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech, Fall 2018</span>
<hr>

The code for this project can be found in <a href="https://github.com/raghavrajmittal/PetSwap">this repository</a>. It has been adapted from the following open source repositories:
<ul>
  <li><a href="https://github.com/matterport/Mask_RCNN">Mask R-CNN official implementation</a></li>
</ul>



<!-- Goal -->
<h2>Abstract</h2>
One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.



<!-- <br><br> -->
<!-- figure -->
<!-- <h2>Teaser figure</h2>
A figure that conveys the main idea behind the project or the main application being addressed. (This one is from <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a>.)
<br><br> -->
<!-- Main Illustrative Figure -->
<!-- <div style="text-align: center;">
<img style="height: 200px;" alt="" src="images/alexnet.png">
</div> -->




<!-- <br><br> -->
<!-- Introduction -->
<!-- <h2>Introduction / Background / Motivation</h2>
<h4>What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon.</h4>
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.

<h4>How is it done today, and what are the limits of current practice?</h4>
Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

<h4>Who cares? If you are successful, what difference will it make?</h4>
Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. -->




<br><br>
<!-- Approach -->
<h2>Approach</h2>
<h4>What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach?</h4>
Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

<h4>What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?</h4>
Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.




<br><br>
<!-- Results -->
<h2>Experiments and Results</h2>

<h4>Experimental setup</h4>
We will divide the dataset into a 80% training and 20% testing split. In order to test the functionality of our application, we will take the testing data and measure the sum of squared errors (SSE) of the clusters as well as the similarity between the input image and the returned output image. 

<h4>Datasets</h4>
We plan to use existing datasets containing images of cats and dogs. We found two Kaggle datasets:
<div><a href="https://www.kaggle.com/crawford/cat-dataset">Cat Dataset</a>
<div><a href="https://www.kaggle.com/tongpython/cat-and-dog#dog.4003.jpg">Cat and Dog</a>
<br><br>Additionally, if needed, we can scrape Google Images for more images if we find the datasets do not contain enough images. 

<h4>Existing code</h4>
We plan to use code from several GitHub repositories:
<div><a href="https://github.com/matterport/Mask_RCNN">Mask R-CNN</a>
<div><a href="https://github.com/pochih/CBIR">Content-based image retrieval (CBIR) system</a>
<div><a href="https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html">GrabCut algorithm</a>
<br><br>Also, we plan to use an existing implementation of a clustering algorithm: either k-means or expectation maximization (EM), both of which are included in scikit-learn:
<div><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">k-means</a>
<div><a href="https://scikit-learn.org/stable/modules/mixture.html">EM</a>

<h4>What we will implement</h4>
We are implementing the pipeline to solve the problem end-to-end. Specifically, we need to create a useful image representation that captures the key information about the images. This could be a combination of texture, color, etc.

<h4>Defining success</h4>
We define success for the project to be the elbow of the k vs SSE curve and having a distance of 10% (of the mean distance) between input and output images. 

<h4>Experiments</h4>
<h5>Foreground feature representation</h5>
We can try examining different features of the foreground. As a baseline, we can add every image pixel into a histogram. However, there is a concern that this will be too computationally expensive. It could be more effective and simpler to consider specific features of the image such as texture or color. 
<h5>Distance function</h5>
We can experiment with using different distance functions. To calculate similarity between histograms, two common functions are Euclidean distance and chi-squared. Unlike Euclidean which penalizes aboslute difference, chi-squared penalizes relative difference. Therefore, we expect the final clusters that result from using these two distance functions to be quite different. 
<h5>Clustering algorithm</h5>
We can try both k-means and EM clustering methods. The main difference is that k-means hard clusters whereas EM soft clusters. Whereas k-means assigns each point to a cluster definitively, EM uses a probabilistic approach to assign probabilities of belonging to each cluster for each point. Both could provide interesting results in this project since we expect k-means to give cleaner results faster but EM to perhaps find some insights missing from k-means.
<br><br>Additionally, we can try varying the value of k in k-means. This is key to finding meaningful groups in the dataset. If the clusters are too small, similar images may not be grouped together. On the other, clusters that are too large will group dissimilar images together.  






<br><br>
<!-- Main Results Figure -->
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="images/results.png">
</div>



<br><br>
<!-- Footer -->
  <hr>
  <footer>
  <p>Â© Hemanth Chittanuru, Kenny Scharm, Raghav Raj Mittal, Sarah Li</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
